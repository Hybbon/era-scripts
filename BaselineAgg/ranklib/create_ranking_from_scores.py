"""This script receives a file containing a list of scores given to pairs 
(user,item) and creates a file containingone ranking for each user.
We can user different score files. The ones generated by the RankLib have the 
following format:

user_id\titem_pos\tscore

Other formats to be add CRF, Libfm....

"""

import os
import sys
import argparse
import pandas as pd
import numpy as np

def parse_args():

    p = argparse.ArgumentParser()

    p.add_argument("-map",type=str,help="Map file")
    p.add_argument("-scores",type=str,
        help="File containing the scores returned by some algorithm")
    p.add_argument("-o","--out_dir",type=str,
        help="Folder where the output rankings will be saved")
    p.add_argument("-size",type=int,default=10,
        help="Size of the output rank that will be saved")

    return p.parse_args()


"""
return a dictionary containg where the key is a user_id and the value is a list 
containing the items recommend to this item in the same order of the classification
dataset
"""
def read_map(args):
    
    user_items_dict = {}
    with open(args.map) as mapping:
        for map_line in mapping:
            user_id,map_items = map_line.strip().split(':') #get user id
            map_items = map_items.replace("(","").replace(")","").split(";") #break the line in the item mapping
            user_items_dict[int(user_id)] = [] #creates a new entry
            for item in map_items: #each pair (pos,item) are correlated to one line of data_file 
                _,item_id = item.split(',')#gets the item_id, the position is irrelevant in this case 
                user_items_dict[int(user_id)].append(int(item_id))

    return user_items_dict


def read_RankLib_scores(args):

    header = ("user_id","item_pos","item_score")
    types = {"user_id":np.int32,"item_pos":np.int32,"item_score":np.float64}
    scores = pd.read_csv(args.scores,sep="\t",names=header,dtype=types)
    return scores




def construct_rankings(scores,user_map, out_file_path = ""):
    
    sorted_users = sorted(user_map.keys())
    users_rankings = {}
    if out_file_path:
        out_file = open(out_file_path, 'w')

    for user_id in sorted_users:
        user_item_scores = scores[scores.user_id==user_id].sort_values(by ='item_score',ascending=False)
        user_item_scores = user_item_scores[:10]
        items_pos = list(user_item_scores.item_pos)
        items_scores = list(user_item_scores.item_score)

        str_aux = str(user_id)+"\t["
        users_rankings[user_id] = []
        for item_pos,item_score in zip(items_pos,items_scores):
            item_id = user_map[user_id][item_pos]
            users_rankings[user_id].append((item_id,item_score))
            str_aux += "{0}:{1},".format(item_id,item_score)
        
        str_aux = str_aux[:-1]+']'
        str_aux += '\n'
        if out_file_path:
            out_file.write(str_aux) 

   
    if out_file_path:
        out_file.close()
    
    return users_rankings
        
    

if __name__ == "__main__":

    args = parse_args()
    scores = read_RankLib_scores(args)
    user_map = read_map(args)
    rankings = construct_rankings(scores,user_map,args.out_dir)
    



"""Transforma os nossos dados para o formato dos dados das MQ200* da Letor 4
Roda algoritmo de l2r da lemur e salva um modelo (aceita validacao)
Usa o modelo para gerar rankings para os itens presentes no arquivo de teste
    No nosso caso, o arquivo de teste deve ser o arquivo de 'treino' da pasta reeval. Ou seja, o dataset criado a partir dos rankings gerados para a partição train + validation. Vai ser gerada uma lista com os scores de cada um dos pares (user,item) essa lista deve ser ordenada e dada como saída








java -jar RankLib-2.1-patched.jar -train /home/samuel/workspace/Gen_dataset_GPRA/ml100k_plain/classif/u1.train.letor -test /home/samuel/workspace/Gen_dataset_GPRA/ml100k_plain/classif/u1.train.letor -ranker 6 -metric2t NDCG@10 -metric2T ERR@10 -save /home/samuel/workspace/Gen_dataset_GPRA/ml100k_plain/classif/Rank_lib_model.txt


java -jar RankLib-2.1-patched.jar -load /home/samuel/workspace/Gen_dataset_GPRA/ml100k_plain/classif/Rank_lib_model.txt -rank /home/samuel/workspace/Gen_dataset_GPRA/ml100k_plain/reeval/u1.train.letor -score /home/samuel/workspace/Gen_dataset_GPRA/ml100k_plain/reeval/u1.rankLib.scores"""




