#!/usr/bin/env python3

"""
mmltohyper.py
=============
Converts a MML-format dataset to Hyper's format and structure
-------------------------------------------------------------

**IMPORTANT**: This script's output does not work as intended with the
provided HyPER script. Refer to the last section of this docstring.

This script is used to convert a bunch of MML-format rating files and
recommender results so that they can be aggregated via HyPER_. HyPER
is a framework for hybrid recommender systems that supports many types
of sources of information for ranking aggregation, but this script
assumes that it'll be used with data from the users' ratings and
recommenders' outputs for these ratings only (no social or similarity
data is taken into account for aggregation).

.. _HyPER: https://github.com/pkouki/recsys2015

Three kinds of input files are needed in order to run this script,
which should be located inside the input directory:

- Recommender files (*.out)
- Test files (*.test)
- Training files (*.base)

The types of files are identified by their extensions, but the
recognition regular expression can be modified through command-line
settings. As expected, the files generated by pre-processing a dataset
and running recommenders through *pre_process.py* and
*run_recommenders.py* have the appropriate format for this script.

The output structure consists of two directories: the top directory
and the weight learning directory. HyPER runs in two distinct phases:
first, it attempts to learn weights for each of the specified rules
for aggregation. Then, it actually aggregates the provided information
sources.

Also, it's important to note that RankingStats also provides a
modified HyPER .groovy script for execution with the output files from
this script. However, it assumes a more specific format, which is the
one used by default for generating files via *pre_process.py* and
*run_recommenders.py*. It has five folds, from *u1* to *u5*, and a
specific list of recommender algorithms. Here is an example of the
expected `input structure`_ for running the script, as well as the
`output structure`_ for reference.

.. _input structure: https://gist.github.com/Blekwave/914c8aa355061d37fb9beac96a1c89e4
.. _output structure: https://gist.github.com/Blekwave/2ad3f00d7a7e43b1aca1d6d0ded54fa3

The provided script can be adapted for different dataset formats,
but details about that will not be provided here.

Running the script is quite simple. The script has no dependencies
in this repository (although it does require numpy, scikit-learn and
pandas), so it can be safely moved to other folders. By default, it
will attempt to convert the files in the current working directory.
This can be changed via the ``-i`` flag. It'll output the hyper-ready
data in a directory called "hyper_out" inside the input folder.

Examples::

    python mmltohyper.py -i bases/100k/reeval/

    python mmltohyper.py -i bases/100k/ -e ".*\\.validation"

The second call sets the regex for test files to any ".validation"
files. When using data generated by RankingStats' *pre_process.py*,
one must specify this when dealing with the three-way split, in order
to use the validation files as the testing partition.

Running HyPER
-------------

Instructions for installing HyPER are available at its repository on
Github. In order to use the modified script provided with the
converted files generated by this script, a few more steps are needed.
These will refer to the data directory (the one with the *lastfm* and
*yelp* dataset files and recommender outputs) as ``/hyper/data/`` and
to the HyPER source directory as ``/hyper/src/`` for simplicity.

In an actual install, these are likely to be:

- data: `psl-example/data/`
- sources: `psl-example/src/main/java/edu/umd/cs/example/`

Instructions:

1. Run this script and generate the ``hyper_out`` directory::
    python mmltohyper.py -i bases/100k/reeval/
2. Move it to Hyper's data directory::
    mv bases/100k/reeval/hyper_out/ /hyper/data/hyper_out/
3. Copy the provided HyPER script to HyPER's source folder::
    cp hyper/RankingStats.groovy /hyper/src/
4. Change directory to HyPER's::
    cd /hyper/
5. Recompile HyPER::
    mvn compile
6. Run HyPER with the new script::
    java -cp ./target/classes:`cat classpath.out` edu.ucsc.cs.model.RankingStats


Conversion process
------------------

The conversion to the HyPER format is not straight-forward: a single
source file can be used for generating many other files.

Recommender files
~~~~~~~~~~~~~~~~~

These files are transformed into lists of recommendations, with the
original scores rescaled to the [0, 1] interval. They are, then,
saved to ``weight_learning/<filename>``, in the format::

    <user_id> <item_id> <score>

One recommended item per line.

Test files
~~~~~~~~~~

Test files are used to generate two files:

- ``<fold_prefix>.test``: original test file, with ratings rescaled to
  [0, 1].
- ``<fold_prefix>.topredict``: list of predictions to be made in the
  aggregation phase. Essentially a list of the ratings in the test
  file, without the scores.

Training files
~~~~~~~~~~~~~~

Training files are used to generate many different files:

- ``<fold_prefix>.train``: original training file, with ratings
  rescaled to [0, 1].

A new train-test cross-validation split is, then, performed on the
rescaled ratings above. By default, training keeps 90% of the ratings,
but this can be changed via command line parameters. This new split
is used to generate the following files:

- ``weight_learning/<fold_prefix>.train``: the training ratings of the
  new split.
- ``weight_learning/<fold_prefix>.rated``: same as above, but without
  the scores, just a list of the items rated by each user.
- ``weight_learning/<fold_prefix>.topredict``: the test ratings of the
  new split, but without the scores, just a list of the items rated
  by each user in the fold.

Finally, a 40% sampling of the new training fold is done, and these
ratings are used as the test fold for weight learning (the fraction
is parameterizable through command-line settings):

- ``weight_learning/<fold_prefix>.test``: 40% sample of the new
  training fold.

Other files
~~~~~~~~~~~

``u.proc.data``, created by *pre_process.py*, is also used in this
script in order to generate lists of users, items and ratings in the
entire dataset. Three more files are created:

- items
- rated
- users

What currently doesn't work
---------------------------

Despite the conversion above, the output files, together with the
HyPER script, will still cause a crash. This is due to the way the
current recommenders work: they generate a ranking of the top N items.
HyPER, on the other hand, expects recommenders to predict scores for
a list of items, and that all recommenders rate the same items for a
given user.

The items for which the recommenders should generate predictions are
the ones in the ``.topredict`` files in the weight learning directory.

This is not currently the case and, therefore, there's no way to
straightforwardly convert MML's item recommenders' outputs to the
HyPER format. Some ways to fix this would be to:

- Make the recommenders generate predictions for the items in the
  ``topredict`` for each user somehow.
- Generate all possible predictions for a user and filter these to
  the ones in the ``topredict`` file.
- Use the current recommendations for a user-item pair from the
  ``topredict`` file whenever possible. If a pair hasn't been scored
  by a recommender, set its score to the lowest possible value.
"""
import sys
import argparse
import os
import re
import pandas as pd
import numpy as np
from sklearn.cross_validation import train_test_split


float_regex = r'[+-]?(?:\d+(?:\.\d*)?|\.\d+)(?:[eE][+-]?\d+)?'
item_regex_str = "(\d+):({0})".format(float_regex)
item_regex = re.compile(item_regex_str)


# FILE INPUT FUNCTIONS

def mml_to_frame(addr):
    """Read MML recommender results to a Pandas DataFrame"""
    tuples = []
    for line in open(addr):
        spl = line.split("\t")
        user_id = int(spl[0])
        items_and_ratings = item_regex.findall(spl[1])
        for item_id_str, rating_str in items_and_ratings:
            tuples.append((user_id, int(item_id_str), float(rating_str)))
    return pd.DataFrame.from_records(tuples, columns=("user_id", "item_id", "rating"))


def read_ratings(addr):
    """Read a csv file of ratings to a Pandas DataFrame"""
    return pd.read_csv(addr, sep="\t", names=("user_id", "item_id", "rating"),
                       header=None)


# FRAME PROCESSING FUNCTIONS

def normalize_ratings(frame):
    """Rescales a frame of ratings from 0-5 to the hyper format."""
    frame = rescale_frame_ratings(frame, min_rating=0, max_rating=5)
    return frame


def rescale_frame_ratings(frame, min_rating=None, max_rating=None):
    """Rescales ratings in a frame to new min and max ratings"""
    min_rating = frame.rating.min() if min_rating is None else min_rating
    max_rating = frame.rating.max() if max_rating is None else max_rating

    def normalize(rating):
        return (rating - min_rating) / (max_rating - min_rating)

    frame.rating = frame.rating.apply(normalize)
    return frame


def list_rated(f):
    """Lists strings for items rated by each user."""
    return ["{}\t{}".format(int(user_id), int(item_id))
            for index, (user_id, item_id, rating) in f.iterrows()]


# FILE OUTPUT FUNCTIONS

def save_iterable(addr, it):
    """Saves an iterable which iterates over strings to a file.

    The strings are separated by newlines."""
    with open(addr, "w") as f:
        for item in it:
            f.write("{}\n".format(item))


def save_frame(addr, frame):
    """Saves a pandas dataframe to a csv."""
    frame.to_csv(addr, sep="\t", index=False, header=False, float_format="%.3f")


# OTHER AUX FUNCTIONS

def gen_aux_files(input_dir, output_dir):
    """Generates auxiliary files for Hyper

    Output files:
        users - list of users in the dataset
        items - list of items in the dataset
        rated - list of all ratings in the dataset
    """
    f = read_ratings(os.path.join(input_dir, "u.proc.data"))
    save_iterable(os.path.join(output_dir, "users"), f.user_id.unique())
    save_iterable(os.path.join(output_dir, "items"), f.item_id.unique())

    rated = list_rated(f)

    save_iterable(os.path.join(output_dir, "rated"), rated)


def group_files(input_dir, args):
    """Groups files from a dir into three groups: training, testing
    and mml result files."""
    train_files, test_files, mml_files = [], [], []

    mml_wildcard = re.compile(args.mml_wildcard)
    train_wildcard = re.compile(args.train_wildcard)
    test_wildcard = re.compile(args.test_wildcard)

    for filename in os.listdir(input_dir):
        if mml_wildcard.search(filename):
            mml_files.append(filename)
        elif train_wildcard.search(filename):
            train_files.append(filename)
        elif test_wildcard.search(filename):
            test_files.append(filename)
        else:
            print("Ignored " + filename)
    return train_files, test_files, mml_files


def prefix(filename):
    """Get a filename's fold prefix"""
    return filename[:2]


def process_train_file(filename, input_dir, output_dir, wl_dir,
                       wl_train_frac, wl_test_frac):
    """Generate Hyper files from a training file

    Files created:
        - uX.train: normalized training data
        - wl/uX.train: wl_train_frac% of the training data
        - wl/uX.test: t% of the (1 - c)% file above
        - wl/uX.rated: wl/train file, without ratings
        - wl/uX.topredict: (1 - wl_train_frac)% of the training data,
                           without ratings
    """
    p = prefix(filename)
    input_file = os.path.join(input_dir, filename)

    train_frame = read_ratings(input_file)
    train_frame = normalize_ratings(train_frame)
    train_file = os.path.join(output_dir, p + ".train")
    save_frame(train_file, train_frame)

    wl_file = os.path.join(wl_dir, p + ".{ext}").format

    wl_train_frame, wl_topredict_frame = (
            train_test_split(train_frame, train_size=wl_train_frac))
    save_frame(wl_file(ext="train"), wl_train_frame)

    wl_test_frame = wl_train_frame.sample(frac=wl_test_frac)
    save_frame(wl_file(ext="test"), wl_test_frame)

    save_iterable(wl_file(ext="rated"), list_rated(wl_train_frame))
    save_iterable(wl_file(ext="topredict"), list_rated(wl_topredict_frame))


def process_test_file(filename, input_dir, output_dir):
    """Generate Hyper files from a test file

    Files created:
        - uX.test: normalized test data
        - uX.topredict: file above, without ratings
    """
    p = prefix(filename)
    input_file = os.path.join(input_dir, filename)

    frame = read_ratings(input_file)
    frame = normalize_ratings(frame)
    test_file = os.path.join(output_dir, p + ".test")
    save_frame(test_file, frame)

    topredict_file = os.path.join(output_dir, p + ".topredict")
    save_iterable(topredict_file, list_rated(frame))


def process_mml_file(filename, input_dir, mml_dir):
    """Generate Hyper files from MML-formatted recommender results

    Files created:
        - wl/uX-alg.out: converted recommender results
    """
    input_file = os.path.join(input_dir, filename)
    hyper_file = os.path.join(mml_dir, filename)
    frame = mml_to_frame(input_file)
    frame = rescale_frame_ratings(frame)
    save_frame(hyper_file, frame)


WL_DIR_NAME = "weight_learning"


def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument("-i", "--input_dir", type=str, default=".",
            help="directory containing the files to be converted")
    p.add_argument("-o", "--output_dir", type=str, default="hyper_out/",
            help="output directory, relative to the input address "
            "(default: %(default)s)")
    p.add_argument("-m", "--mml_wildcard", type=str, default=r".*\.out",
            help="regex for the mml-format recommender output files "
            "(default: %(default)s)")
    p.add_argument("-t", "--train_wildcard", type=str, default=r".*\.base",
            help="regex for the training rating files "
            "(default: %(default)s)")
    p.add_argument("-e", "--test_wildcard", type=str, default=r".*\.test",
            help="regex for the test rating files")
    p.add_argument("-c", "--wl_train_frac", type=float, default=0.9,
            help="fraction of the training ratings for the wl training fold")
    p.add_argument("-d", "--wl_test_frac", type=float, default=0.4,
            help="fraction of the wl training fold for the wl test fold")
    return p.parse_args()


def main():
    args = parse_args()

    input_dir = args.input_dir
    output_dir = os.path.join(args.input_dir, args.output_dir)
    wl_dir = os.path.join(output_dir, WL_DIR_NAME)

    if not os.path.exists(wl_dir):
        os.makedirs(wl_dir)

    gen_aux_files(input_dir, output_dir)


    train_files, test_files, mml_files = group_files(input_dir, args)
    for filename in train_files:
        process_train_file(filename, input_dir, output_dir, wl_dir,
                args.wl_train_frac, args.wl_test_frac)

    for filename in test_files:
        process_test_file(filename, input_dir, output_dir)

    for filename in mml_files:
        process_mml_file(filename, input_dir, wl_dir)


if __name__ == '__main__':
    main()
